{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import gc\n",
    "import torchvision.datasets as dset\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import HTML\n",
    "from zipfile import ZipFile\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "import kaggle\n",
    "import requests\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Ordner ablegen\n",
    "#Ordner wird erstellt\n",
    "os.makedirs('dataGPGAN')\n",
    "#Dateien werden entpackt nach Ordner\n",
    "with ZipFile('animefaces/anime-faces.zip', 'r') as f:\n",
    "  f.extractall('GPGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haupteingaben\n",
    "#Batch-Größe\n",
    "batch_size = 64\n",
    "\n",
    "#Anzahl der Epochen\n",
    "epoch_nr = 200\n",
    "\n",
    "#Learning Rate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#GPUs die zur verwendung stehen (Optional)\n",
    "ngpu = 1\n",
    "\n",
    "#WGAN Master\n",
    "#Kritische Wiederholungen\n",
    "critic_iterations = 5\n",
    "\n",
    "#Lambda\n",
    "lmbd = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU wählen, wenn verfügbar\n",
    "dv = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "#Datenpfad wird angegeben (Ordner wurde zuvor erstellt, Daten wurden via Kaggle herunter geladen)\n",
    "data_path = \"GPGAN\"\n",
    "\n",
    "#Datenset erstellt\n",
    "dataset = dset.ImageFolder(root=data_path,\n",
    "                           transform=transforms.Compose([                               #Mehrere Transformationen am Datenset werden zusammen vorgenommen\n",
    "                               transforms.Resize(64),                                   #Eingegebene Bildaten werden auf die entsprechende Größe gebracht\n",
    "                               transforms.CenterCrop(64),                               #Schneidet das Bild zu, ausgehend von der Bildmitte\n",
    "                               transforms.ToTensor(),                                   #Bilddateien werden zu Tensor konvertiert \n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  #Tensoren werden normalisiert (Kanal, Weite, Höhe)\n",
    "                           ]))\n",
    "\n",
    "#Dataloader wird erstellt\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomisierte Initialisierung der Gewichte\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klassenerstellung Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            #Eingebae eines z_vectors zum Auffalten\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
    "            #Normalisierung\n",
    "            nn.BatchNorm2d(512),\n",
    "            #ReLu-Aktivierungsfunktion für Nichtlinearität\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            #Zielgröße 64 erreicht\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            #Ausgabe von 3 Kanälen, da es sich um eine RGB Bilddatei handelt\n",
    "            #Tanh-Aktivierungsfunktion für einen Wert zwischen [-1;+1]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialiserung des Generators\n",
    "gene = Generator(ngpu).to(dv)\n",
    "#Randomisiert initialisierte Gewichte werden auf den Generator angewandt\n",
    "gene.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klassenerstellung Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            #Eingebae eines der drei RGB-Kanäle zum Auffalten ab der Bildgröße\n",
    "            #LeakyReLu-Aktivierungsfunktion für Nichtlinearität, vermindert sterbende Neuronen\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            #Normalisierung \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisierung des Discriminators\n",
    "disc = Discriminator(ngpu).to(dv)\n",
    "#Randomisiert initialisierte Gewichte werden auf den Discriminator angewandt\n",
    "disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise und Optimizer erstellen\n",
    "\n",
    "#Feste Batch-vectoren definieren um den Generator-fortschritt im Bezug auf den Anfang festzustellen\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=dv)\n",
    "\n",
    "#Optimizer für den Diskriminator wird festgelegt\n",
    "#Algorithmus berechnet einen exponentiellen gleitenden Durchschnitt des Gradienten und des quadrierten Gradienten, Parameter steuern die Abklingraten\n",
    "disc_optimizer = optim.Adam(disc.parameters(), lr=learning_rate, betas = (0.0, 0.9))\n",
    "#Optimizer für den Generator wird festgelegt\n",
    "gene_optimizer = optim.Adam(gene.parameters(), lr=learning_rate, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainingsschleife\n",
    "#Ordner wird erstellt\n",
    "os.makedirs('savesGPGAN')\n",
    "\n",
    "#Arrays für Bilder, Generator & Diskriminator - Losses\n",
    "img_list = []\n",
    "gene_losses = []\n",
    "disc_losses = []\n",
    "iters = 0\n",
    "safe = 0\n",
    "\n",
    "#Schleife für Wiederholung nach Anzahl der Epochen\n",
    "for epoch in range(epoch_nr):\n",
    "    #Schleife für jede Batch des Dataloaders\n",
    "    for i, (real_data,_) in enumerate(dataloader):\n",
    "\n",
    "        data = real_data.float().shape[0]\n",
    "\n",
    "        for _ in range(critic_iterations):\n",
    "\n",
    "            disc_optimizer.zero_grad()\n",
    "\n",
    "            local_noise = torch.randn(data, 100, 1, 1).to(dv)\n",
    "\n",
    "            r_img = real_data.to(dv)\n",
    "\n",
    "            f_img = gene(local_noise)\n",
    "\n",
    "            output_r = disc(r_img)\n",
    "\n",
    "            output_f = disc(f_img)\n",
    "\n",
    "            epsilon = torch.rand(r_img.shape[0], 1, 1, 1).to(dv)\n",
    "\n",
    "            interpolated = epsilon * r_img + (1 - epsilon) * f_img\n",
    "\n",
    "            output_d = disc(interpolated)\n",
    "\n",
    "            grad = torch.autograd.grad(outputs = output_d, inputs = interpolated, grad_outputs = torch.ones(output_d.size(), device = dv), create_graph = True, retain_graph = True, only_inputs = True, allow_unused = True)[0]\n",
    "\n",
    "            gp = ((grad.norm(2, dim = 1) - 1) ** 2).mean()\n",
    "\n",
    "            loss_disc = (output_f-output_r).mean() + gp.mean() * lmbd\n",
    "\n",
    "            loss_disc.backward()\n",
    "\n",
    "            disc_optimizer.step()   \n",
    "\n",
    "        gene_optimizer.zero_grad()\n",
    "\n",
    "        local_noise = torch.randn(data, 100, 1, 1).to(dv)\n",
    "\n",
    "        output = -disc(gene(local_noise))\n",
    "\n",
    "        loss_gene = output.mean()  \n",
    "\n",
    "        loss_gene.backward()\n",
    "        \n",
    "        gene_optimizer.step()\n",
    "\n",
    "        #Loss Generator wird ans Ende der Liste angehangen \n",
    "        gene_losses.append(loss_gene)\n",
    "        #Loss Discriminator wird ans Ende der Liste angehangen \n",
    "        disc_losses.append(loss_disc)\n",
    "\n",
    "        #Hälfte der Btachgröße / volle Batchgröße\n",
    "        if i % (len(dataloader)) == 0:\n",
    "            print('[%.3i/%.3i] Größe: %.3i Wiederholung: %.i Loss_D: %.4f Loss_G: %.4f' % (epoch, epoch_nr, len(dataloader), iters, loss_disc, loss_gene))\n",
    "\n",
    "            with torch.no_grad():\n",
    "            #Fakes werden an den Generator-Output gehängt\n",
    "                fake = gene(fixed_noise)\n",
    "            #Tensor wird auf Bilddatei gespeichert\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "            #Bilder werden abgespeichert\n",
    "            save_image(img_list[epoch], \"savesGPGAN/Ep%.3i.png\" % (epoch), nrow=1, normalize=True)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Direkter Vergleich\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Echte Bilder\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(dv)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generierte Bilder\")\n",
    "plt.imshow(np.transpose(img_list[-1].cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
